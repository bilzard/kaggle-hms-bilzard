defaults:
  - baseline_efficientnet2d_b0
  - _self_

exp_name: exp100_18ep
description: use loss weight in distillation

architecture:
  model:
    encoder:
      num_eeg_channels: 8

trainer:
  epochs: 18
  use_loss_weights: true
  distillation:
    teacher_exp_name: exp069
    teacher_seed: ${seed}
    target_forget_rate: 0.2
    target_epochs: 4
    use_loss_weights: true
